{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzyHDvx1/OfTTWptrk6u+I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KLAU-S/SRIP2022/blob/main/Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-3pQw1SbhT43"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from keras.datasets import mnist #importing from keras is not working since we require only two dataframes train and test\n",
        "#from torchvision.datasets import MNIST #imports literal images (don't need)\n",
        "#from torch.utils.data import DataLoader #DataLoader loads the mnist img data that we will pass in the MLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from jax.scipy.special import logsumexp\n",
        "import jax\n",
        "from jax import jit, vmap, pmap, grad, value_and_grad"
      ],
      "metadata": {
        "id": "oBmvOkBexn2R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below imports dataset which has images as elements if imported from torchvision, but need numpy array type elements"
      ],
      "metadata": {
        "id": "tOR9A9oR1c8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = MNIST(root='train_mnist', train=True, download=True, transform=None)\n",
        "# test_dataset = MNIST(root='test_mnist', train=False, download=True, transform=None"
      ],
      "metadata": {
        "id": "KOeFuh5m2Ksh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The MNIST data is already split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel image if imported from keras**"
      ],
      "metadata": {
        "id": "Sca8BMcl65Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNU4gGOSwzte",
        "outputId": "7cab6a38-3a96-4662-ecbb-ba82d6d28250"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0].shape)\n",
        "print(y_train[0].shape)\n",
        "print(x_test[0].shape)\n",
        "print(y_test[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al3DS9JHT72b",
        "outputId": "478abc9a-a29e-46e7-c480-0c112c51b1a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "()\n",
            "(28, 28)\n",
            "()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElieeMfgUoQD",
        "outputId": "c18263fd-ce7d-45ed-c141-6540c17e72bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKKJswmqUsMK",
        "outputId": "ab2204e2-d7da-438c-9e4a-f876fe8de6e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnSv7yUBUw9x",
        "outputId": "d4a8071d-1561-42fc-91c5-2794f327ce4e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since its already splitted into 60000 and 10000 we can concatanate and then split into 80:20 "
      ],
      "metadata": {
        "id": "bu7eyjRnYOOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.concatenate([x_train, x_test])\n",
        "y = np.concatenate([y_train, y_test])"
      ],
      "metadata": {
        "id": "zWoBCY9E74Ih"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (10):\n",
        "  print(y[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4xE_3t15vfE",
        "outputId": "4cb6aa81-9cb6-4cbd-b590-0074cb24d7a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "0\n",
            "4\n",
            "1\n",
            "9\n",
            "2\n",
            "1\n",
            "3\n",
            "1\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(x_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77YMThNPzgPj",
        "outputId": "49891083-f0c3-4509-97f8-cf6a9d4089bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting MNIST dataset with 80:20 train:test"
      ],
      "metadata": {
        "id": "8PS4nWZI9OiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training_data, testing_data = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "train_ratio = 0.8\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=(1-train_ratio), random_state=42)"
      ],
      "metadata": {
        "id": "BHLthOddL7--"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#validating\n",
        "###since, 70000 * 80% = 56000 splitting success"
      ],
      "metadata": {
        "id": "aW75tW4nbwEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape) \n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk5yD4i19eFk",
        "outputId": "883a24a1-5adb-475c-b4b9-45934ca1d3f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 28, 28)\n",
            "(56000,)\n",
            "(14000, 28, 28)\n",
            "(14000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concat_train = pd.concat([X_train, pd.DataFrame(Y_train)])"
      ],
      "metadata": {
        "id": "w9wDWcKkrz7B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = X_train[0]\n",
        "img2 = Y_train[0]\n",
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdWMCaMn-tyk",
        "outputId": "00c0d300-8826-43b4-c5ad-326f4f9b1c54"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl7wNQKW_8zK",
        "outputId": "8384738b-c104-4571-dad8-57e1afc8827f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.ravel(X_train)\n",
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzoGynCA-7I1",
        "outputId": "28fc06ce-7ceb-48c7-a60a-d7124e446f87"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ALL ACTIVATION FUCTIONS"
      ],
      "metadata": {
        "id": "9WRTNGqaBqWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return np.maximum(x, np.zeros_like(x))"
      ],
      "metadata": {
        "id": "DHFrV5buBoYE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    x = x-np.max(x)\n",
        "    return np.exp(x) / np.sum(np.exp(x))"
      ],
      "metadata": {
        "id": "opOQSqt1ByGF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crossentropy(y, yhat):\n",
        "    return -np.nansum(y*np.log(yhat), axis=1)"
      ],
      "metadata": {
        "id": "lirzcQerB4v6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradient Descent \n",
        "- It is a first-order optimization technique used to find the local minimum or optimize the loss function. It is also known as the parameter optimization technique.\n",
        "- It is easy to find the value of slope and intercept using a **closed-form solution** But when you work in Multidimensional data then the technique is so costly and takes a lot of time Thus it fails here. So, the new technique came as Gradient Descent which finds the minimum very fastly.\n",
        "\n",
        "- An equation is said to be a **closed-form solution** if it solves a given problem in terms of functions and mathematical operations from a given generally-accepted set. For example, an infinite sum would generally not be considered closed-form."
      ],
      "metadata": {
        "id": "AWwOyoH1Q79g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##To implement gradient descent we can use jax.grad function but implementing from scratch<br>\n",
        "```python\n",
        "jax.grad(fun, argnums=0, has_aux=False, holomorphic=False, allow_int=False, reduce_axes=())[source]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ycBsnoB9R6Sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(self, x, y, iterations):\n",
        "        for i in range(iterations):\n",
        "            Xi = x\n",
        "            Xj = self.sigmoid(Xi, self.wij)\n",
        "            yhat = self.sigmoid(Xj, self.wjk)\n",
        "            # gradients for hidden to output weights\n",
        "            g_wjk = np.dot(Xj.T, (y - yhat) * self.sigmoid_derivative(Xj, self.wjk))\n",
        "            # gradients for input to hidden weights\n",
        "            g_wij = np.dot(Xi.T, np.dot((y - yhat) * self.sigmoid_derivative(Xj, self.wjk), self.wjk.T) * self.sigmoid_derivative(Xi, self.wij))\n",
        "            # update weights\n",
        "            self.wij += g_wij\n",
        "            self.wjk += g_wjk\n",
        "        print('The final prediction from neural network are: ')\n",
        "        print(yhat)"
      ],
      "metadata": {
        "id": "1RhAqVFuUWGG"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}